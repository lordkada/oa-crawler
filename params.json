{"name":"Oa-crawler","tagline":"oa-crawler","body":"\r\n[Permalink](https://dl.dropboxusercontent.com/u/15982375/hacking-twitter-and-be-suspended-in-less-than.html \"Permalink to opinionage, voices from the crew\")\r\n\r\n# opinionage, voices from the crew\r\n\r\nHey guys,\r\n\r\na few weeks ago I was struggling to boost traction to our website when I had a lunch in a shiny day in San Francisco with my friend Federico (Feroldi). He unconsciously was the trigger in this story ;-).\r\n\r\nWhile Federico’s words where still echoing in my head (“I’m too lazy, so I let my computer work... not me!”) I was puzzling over a simple question:** “how can I discover and engage Twitter users to Opinionage contents with a simple program?” **\r\n\r\nFurthermore I was keeping at the same time an eye on the Twitter rules to figure out what is allowed and what is not (get a walk around their “spam and abuse section” if you didn’t, it provides a lot of unclear and ambiguous definitions... don’t you agree with me?) \r\n\r\n**So, it was clear enough that if I wanted to build such an “automaton”, it should be animated by an algorithm accurate as a sniper**: finding relevant tweets and  engaging people with personal messages, but at the same time avoiding any spamming behavior and consuming Twitter’s API at the maximum allowed (low) rate. Furthermore I should assure that each personal message must be written in an understandable language by target people (what about writing in english to somebody who speaks Chinese only?)... Cool enough?!? I think so...\r\n\r\n**The first big challenge was about translating Opinionage topics into meaningful keywords to be used as query text to the Twitter’s search API**. \r\n\r\nIf you don’t know what an Opinionage topic is, let’s imagine a big question/issue about something you really care about that you want to publicly debate; the scheme  is the “round table” where the most shared opinion or proposal “socially emerge” (do you recall the legendary King Arthur’s round table? The idea was to place the theme at the center of the discussion, not the people. We’re doing the same thing, but virtually!).\r\n\r\nIn brief a topic means a lot of text!!! So if you need to extract some meaningful keywords to build your query then... good luck!!! At least you have to rely on some sophisticated semantic API or engines. But they definitely weren’t my solution, not just for a simple hack!\r\n\r\nThe solution brilliant but obvious was just there under my eyes: instead of using these huge texts, I just needed the topic tags: simple keywords used by authors to label the topic. They define both the content (semantic) and the language! \r\n\r\nOur tags are stored in our graph db (neo4j), so I just needed to follow the right relationship:\r\n\r\n> tags = topic_node.outgoing(:tag).inject([]) do |memo, tag_node|\r\n>\r\n>    memo \r\n> end\r\n\r\nThen as a general strategy I decided to use the maximum number of available tags to find relevant tweets, setting a lower limit of 3 (=@min_allowed_tags). This gave me a good confidence on the result quality.\r\n\r\n> if tags.count >= @min_allowed_tags\r\n>\r\n>    sorted_twitters = []\r\n>\r\n>    max_range_tags  = [tags.count, @max_allowed_tags].min\r\n>\r\n>    (@min_allowed_tags..max_range_tags).each do |i|\r\n>\r\n>       tags.combination(max_range_tags-(i-@min_allowed_tags)).each do |tag_combination|\r\n>\r\n>          search_twitters(tag_combination.to_a.join(\" \")).each do |twitter|\r\n>\r\n>             sorted_twitters = build_sorted_hash_array sorted_twitters, twitter, :followers\r\n>\r\n>          end\r\n>\r\n>       end\r\n>\r\n>     end\r\n>\r\n> end\r\n\r\nTo save results and assure that I will contact each Twitterer only once, I used a support table (ContactedUsers)\r\n\r\n> contacted_twitters = 0\r\n>\r\n> sorted_twitters.each do |twitter|\r\n>\r\n> if ContactedUsers.find_by_twitter_name(twitter[:display_name]).nil?\r\n>\r\n>    contacted_user = ContactedUsers.new :twitter_id   => twitter[:twitter_id],\r\n>\r\n>                                        :twitter_name => twitter[:display_name],\r\n>\r\n>                                        :followers    => twitter[:followers],\r\n>\r\n>                                        :search_key   => twitter[:search_string],\r\n>\r\n>                                        :tweet        => twitter[:tweet],\r\n>\r\n>                                        :tweet_id     => twitter[:tweet_id],\r\n>\r\n>                                        :topic_id     => topic.id,\r\n>\r\n>                                        :topic_title  => topic.question_text,\r\n>\r\n>                                        :twitted      => false\r\n>\r\n>    contacted_user.save!\r\n>\r\n>    contacted_twitters += 1\r\n>\r\n> end\r\n\r\nBefore going on, let me say that I decided to use a producer-consumer pattern: the former was the analyzer as stated above, the latter was the “twitterer engager”. In this configuration, the ContactedUsers table was the “stack” between the two. This scheme allowed me to pause the procedure and start again without loosing any data (it happened many times at the beginning before I slowed the Twitter API call...)\r\n\r\nThe twitterer engager’s job (the consumer) was about sending a “personal message” to selected people. I decided to use the topic question/claim text and gently truncate it to keep tweets under 140 characters.\r\n\r\nTo be more effective I also decided to follow the user first, then to reply his tweet (the tweet I discovered in the analysis process) with the “personal message”!\r\n\r\n>  user      = results[rand(results.count)]\r\n>\r\n>  url       = \"[http://www.opinionage.com/t/#{user.topic_id}][1]\"\r\n>\r\n>  avail_len = 140 - \"@#{user.twitter_name}  #{url}\".length\r\n>\r\n>  text       = (user.topic_title.length > avail_len) ? user.topic_title[0, avail_len-3]+\"...\" : user.topic_title\r\n>\r\n>  tweet_text = \"@#{user.twitter_name} #{text} #{url}\"\r\n>\r\n>   Twitter.follow user.twitter_name\r\n>\r\n>  Twitter.update tweet_text, :in_reply_to_status_id => user.tweet_id\r\n>\r\n>  user.twitted       = true\r\n>\r\n>  user.mention_tweet = tweet_text\r\n>\r\n>  user.save\r\n\r\n**In few hours I wrote less than 200 of Ruby LOCs that worked like a charm...**Let me show you some tweets to appreciate the quality of mentions and contents:\r\n\r\n1) about the Facebook’s IPO\r\n\r\n@drrichjlaw said: **More signs of social media bubble bursting: Facebook reveals revenue &amp; profit slide. Haven't even IPO'd yet!**\r\n\r\nautomaton's reply: **@drrichjlaw Do you think Facebook IPO will boost the next internet bubble?**\r\n\r\n2) about the Euro’s crisis\r\n\r\n@RicHolden said: **IMF recently upgraded UK growth forecast for 2012 full year &amp; predict UK will grow faster than either France or Germany...**\r\n\r\nautomaton's reply: **@BrandonLewis Can Europe be saved?**\r\n\r\n3) about Italian government (Italian language)\r\n\r\n@folksonomia said: **Monti acquista altre 400 Auto Blu per un valore di 10 milioni di euro. Noi i sacrifici...**\r\n\r\nautomaton's reply: **@folksonomia La manovra finanziaria salverà l'Italia dal default?**\r\n\r\nIn just 2 days the program has analyzed thousand of profiles and tweeted about 300 times:\r\n\r\n  * **~30% of engaged users replied on Twitter**\r\n  * **~5% became active users on Opinionage**\r\n  * **0 people mentioned Opinionage as spam**\r\n\r\n**Despite a little bit slow (due to the Twitter API’s rate limit) it was infallible: a real sniper!!!**\r\n\r\nI was so satisfied and excited about it until... at the end of the second day, Twitter suspended the account with a laconic \"too many mentions\" :-(\r\n\r\nOf course, I've written to the support team to learn more, because I haven't still really realized what rule I exactly infringed... but I've got no answer yet!\r\n\r\n**So, the lessons learned?**\r\n\r\n  * Sometimes the most impressive results come from tremendously easy things\r\n  * There's a subtle difference between \"spamming\" and \"advertising\"\r\n  * Twitter is a real gold mine!\r\n\r\n@lordkada\r\n\r\nPS if you are curious about the full code, pls contact me ;-)\r\n\r\nPS2 the account was reinstated ;-)\r\n\r\n   [1]: http://livepage.apple.com/","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}